### 2020-08-11

-----
##### 1. 학습 날짜
- 2020-08-11

-----
##### 2. 학습 시간
- 08:00 ~ 20:30


-----
###### 3. 학습 범위 및 주제
- 철학자 문제
- 도커 자연어 처리 환경 구축
- 자연어 처리 기본 익히기

-----
##### 4. 동료 학습 방법
- slack

-----
##### 5. 학습 목표
- 철학자 문제 풀기
- 자연어처리 학습 환경 구축 && 기초학습

-----
##### 6. 과제 제출
- https://github.com/simian114/Philosophers
- https://github.com/simian114/NLP-study

-----
##### 7. 상세 학습 내용

- philosopher
  - 어제부터 계속 죽어야 하는 상황에 죽지 현상이 있었다. 오늘  오후까지 이 문제떄문에 진도가 나가지 못했었는데 문제는 다른게 아니라 ```mutex``` 을 ```init```하지 않고 사용했었기 때문 ... 내일 한번 더 확인해보고 다음 문제로 넘어갈 수 있을거같다.

### 2) 정제, 정규화

- 정제(cleaning): 갖고 있는 코퍼스(데이터 뭉텅이)로부터 노이즈 데이터를 제거한다.
- 정규화(normalization): 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어준다.

- 정제 작업은 토큰화ㅓ 작업에 방해가 되는 부분들을 배제시키고 토큰화 작업을 수행하기 위해서 토큰화보다 앞서서 이루어 지기도 하지만, 토큰화 작업 이후에도 여전히
남아있는 노이즈들을 제거하기 위해 지속적으로 이루어지기도 한다. 완벽한 정제는 어렵기 때문에 어느 수준까지만하자

1. 규칙에 기반한 표기가 다른 단어들의 통합
  - USA와 US는 같은 의미를 가지므로 하나로통합할 수 있다.
  
2. 대, 소문자 통합

3. 불필요한 단어의 제거
  1. 등장 빈도가 적은 단어
  2. 길이가 짧은 단어
  
4. 정규표현식을 이용한 제거
 - html 파서등을 이용해서 가져온 코퍼스에는 html 태그 같은 규칙적으로 달려있는 애들이 있다. 이걸 정규식으로 제거

### 3) 어간 추출 표제어 추출

- 어간 추출과 표제어 추출은 정규화 기법 중 코퍼스에 있는 단어의 개수를 줄일 수 있는 기법

1. 표제어 추출
  - 표제어는 기본 사전형 단어로 생각하면 된다. 예를 들면 ```am, are, is```의 표제어는 ```be```
  
2. 어간 추출
  - 어간(stem)을 추출하는 작ㅇ버을 어간 추출이라고 한다. 어간 추출은 행태학적 분석을 단순화한 버전이라고 볼 수 있다.
  - 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업이라고 보면 된다. 즉 세삼힌 작업이 아님.
  
### 4) 불용어

- 갇고 있는 데이터에서 유의미한 단어 토큰만을 선별하기 위해서는 큰 의미가 없는 단어 토큰을 제거하는 작업이 필요.
- 큰 의미가 없다라는 것은 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들을 의미.
  - 예를 들면 ```I, my, me, over, 조사```등은 자주 등장하지만 실제 의미 분석을 하는데는 기여하는 바가 거의 없다.
  - 이런 단어들을 ```불용어(stopword```라고 한다.
  
  
### 5) 정규 표현식

- 텍스트 데이터를 전처리하다보면, 정규표현식은 아주 유용한 도구가 됨.

### 6) 정수 인코딩

- 컴퓨터는 텍스트 보다는 숫자를 더 잘 처리할 수 있다. 자연어 처리에서는 텍스트를 숫자로 바꾸는 여러가지 기법들이 존재함.
  - 이런 기법들을 본격적으로 적용시키기 위한 첫 단계로는 각 단어를 고유한 정수에 맵ㅎ핑시키는 전처리 작업이 필요할 때가 있다.

### 7) 패딩

- 자연어 처리를 하다보면 각 문장 또는 문서의 길이가 서로 다를 수 있다. 그런데 기계는 길이가전부 동일한 문서들에 대해서는 하나의 행렬로 보고,
한꺼번에 묶어서 처리할 수 있다. 따라서 병렬 연산을 위해서 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업이 필요할 때가 있음.

- 패딩을 할 때는 보통 가장 긴 데이터를 기준으로 한다. 하지만 이 기준이 다른 값들과 괴리가 클 경우, 임의의 값으로 조정해야한다.

- 패딩은 보통 0으로 한다. 물론 강제는 아니다. 0 이 아닌 값으로는 총 데이터 + 1로 하는 경우가 많다.

### 8) 원-핫 인코딩

- 원 핫 인코딩은 문자를 숫자로 바꾸는 여러 ㅂ아법 중 하나.

- 시작하기에 앞서 단어 집합에 대해 정의하자면 단어 집합은 ```서로 다른 단어들의 집합```

- 원 핫 인코딩을 위해서 먼저 해야할 일은 단어 집합을 만드는 것. 텍스트의 모든 단어를 중복을 허용하지 않고 모아 놓으면 이를 단어 집합이라고 한다.
- 그리고 이 단어 집합ㄷ에 고유한 숫자를 부여하는 정수 인코딩을 진행.
- 원 핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부부여하는 단어의 벡터 표현 방식.

- 아래의 과정을 따른다.
  1. 각 단어에 고유한 인덱스를 부여한다 (정수 인코딩)
  2. 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여한다.
  
-----

##### 8. 오늘 학습 내용에 대한 개인적인 총평
- 오전에는 단순한 문제 때문에 시간을 몽땅 날려버렸고 이후에도 다른 사람이랑 너무 놀아버렸다... 그리고 자연어 처리 스터디는 진도를 너무 빨리 나가버려서 실제로 익히는건 하나도 없는거같다. 이러면 안되는데.... 자연어 처리는 언제까지나 세컨드라는걸 명심하자. 정말 중요한건 이너써클이라는걸 명심하자

-----
##### 9. 다음 학습 계획
- 철학자 문제
- cpp module 08 고치기
- 자연어 처리
